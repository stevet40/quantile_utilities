{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29152f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import scipy.stats as ss \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import quantile_utilities as qu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2c50c3",
   "metadata": {},
   "source": [
    "## One-Dimensional Example\n",
    "Having imported our `quantile_utilities` library, let's try making some quantile-quantile (Q-Q) and probability-probability (P-P) plots for a univariate example. We'll do something similar to Figure 1 in the [Thorp et al. (2024)](https://arxiv.org/abs/2402.00930) paper. As our reference distribution we'll use a unit Gaussian, and we'll compare this to a Student-$t$ with two degrees of freedom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d221a7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "x_ref = ss.norm.rvs(loc=0, scale=1, size=N)\n",
    "x_alt = ss.t.rvs(df=2, size=N)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b19fb7",
   "metadata": {},
   "source": [
    "Now, let's use the `qq_plot` and `pp_plot` functions from `quantile_utilities` to compare the distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b05d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({\"font.size\": 15})\n",
    "# we'll set up a 3-panel plot\n",
    "fig, ax = plt.subplots(1, 3, figsize=(12, 4))\n",
    "# we can plot histograms on the first axis...\n",
    "bins = np.linspace(-3, 3, 21)\n",
    "ax[0].hist(x_ref, color=\"tab:blue\", histtype=\"step\", density=True, bins=bins)\n",
    "ax[0].hist(x_alt, color=\"tab:orange\", histtype=\"step\", density=True, bins=bins)\n",
    "ax[0].set_xlabel(\"$x$\")\n",
    "ax[0].set_ylabel(\"$P(x)$\")\n",
    "ax[0].set_xlim(-3, 3)\n",
    "# ...and a Q-Q plot on the second...\n",
    "qu.qq_plot(x_ref, x_alt, B=200, ax=ax[1], xlabel=\"$x^\\\\mathrm{ref}$ quantiles\", ylabel=\"$x^\\\\mathrm{alt}$ quantiles\")\n",
    "ax[1].set_xlim(-3, 3)\n",
    "ax[1].set_ylim(-3, 3)\n",
    "# ... and a P-P plot on the third\n",
    "qu.pp_plot(x_ref, x_alt, B=200, ax=ax[2], xlabel=\"$x^\\\\mathrm{ref}$ cumulative prob.\", ylabel=\"$x^\\\\mathrm{alt}$ cumulative prob.\", markersize=1)\n",
    "ax[2].set_xlim(0,1)\n",
    "ax[2].set_ylim(0,1)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52240a12",
   "metadata": {},
   "source": [
    "We can also try adding a third distribution into the mix by chaining together calls to our plotting functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de20ce1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_alt_2 = ss.skewnorm.rvs(a=2, loc=0, scale=1, size=N)\n",
    "\n",
    "# now we'll use more or less the same plotting calls as before\n",
    "fig, ax = plt.subplots(1, 3, figsize=(12, 4))\n",
    "\n",
    "bins = np.linspace(-3, 3, 21)\n",
    "ax[0].hist(x_ref, color=\"tab:blue\", histtype=\"step\", density=True, bins=bins)\n",
    "ax[0].hist(x_alt, color=\"tab:orange\", histtype=\"step\", density=True, bins=bins)\n",
    "ax[0].hist(x_alt_2, color=\"tab:green\", histtype=\"step\", density=True, bins=bins)\n",
    "ax[0].set_xlabel(\"$x$\")\n",
    "ax[0].set_ylabel(\"$P(x)$\")\n",
    "ax[0].set_xlim(-3, 3)\n",
    "\n",
    "qu.qq_plot(x_ref, x_alt, B=200, ax=ax[1], xlabel=\"$x^\\\\mathrm{ref}$ quantiles\", ylabel=\"$x^\\\\mathrm{alt}$ quantiles\")\n",
    "qu.qq_plot(x_ref, x_alt_2, B=None, ax=ax[1], xlabel=\"$x^\\\\mathrm{ref}$ quantiles\", ylabel=\"$x^\\\\mathrm{alt}$ quantiles\", color=\"tab:green\", diag_linestyle=\"\")\n",
    "ax[1].set_xlim(-3, 3)\n",
    "ax[1].set_ylim(-3, 3)\n",
    "\n",
    "qu.pp_plot(x_ref, x_alt, B=200, ax=ax[2], xlabel=\"$x^\\\\mathrm{ref}$ cumulative prob.\", ylabel=\"$x^\\\\mathrm{alt}$ cumulative prob.\", markersize=1)\n",
    "qu.pp_plot(x_ref, x_alt_2, B=None, ax=ax[2], xlabel=\"$x^\\\\mathrm{ref}$ cumulative prob.\", ylabel=\"$x^\\\\mathrm{alt}$ cumulative prob.\", markersize=1, color=\"tab:green\", diag_linestyle=\"\")\n",
    "ax[2].set_xlim(0,1)\n",
    "ax[2].set_ylim(0,1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127a0475",
   "metadata": {},
   "source": [
    "If we're interested in a numerical summary of these plots, there are a few things we can try. The largest deviation below the diagonal in the P-P plot will be equal to the Kolmogorov-Smirnov (K-S) statistic. We can compute this using `scipy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80fda68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown # things to enable pretty-printing\n",
    "\n",
    "Dks, pks = ss.ks_2samp(x_ref, x_alt)\n",
    "Dks_2, pks_2 = ss.ks_2samp(x_ref, x_alt_2)\n",
    "display(Markdown(\"For Student-$t$ vs. unit Gaussian: $\\mathcal{{D}}_\\mathrm{{KS}}={:.4f}$ ($p={:.4f}$)\".format(Dks, pks)))\n",
    "display(Markdown(\"For skew-normal vs. unit Gaussian: $\\mathcal{{D}}_\\mathrm{{KS}}={:.4f}$ ($p={:.4f}$)\".format(Dks_2, pks_2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b78a849",
   "metadata": {},
   "source": [
    "So, this gives a similar impression to the P-P plot itself. The P-P plot and K-S statistic are most sensitive to shifts in the bulk of the distribution. This is not so big for the Student-$t$, which is most different in the tail behaviour, but it very large for the skew-normal distribution.\n",
    "\n",
    "Another statistic that might be interesting is the $p$-Wasserstein distance between the distributions. This is given by the distance (using the $L^p$ norm) between quantile functions, so it has a nice connection to the Q-Q plot. We've included a function in the `quantile_utilities` library to compute this (by computing the root mean square of the sorted sample arrays)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b1eae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = qu.wp_univariate(x_ref, x_alt)\n",
    "W_2 = qu.wp_univariate(x_ref, x_alt_2)\n",
    "\n",
    "display(Markdown(\"For Student-$t$ vs. unit Gaussian: $\\mathcal{{W}}_2={:.4f}$\".format(W)))\n",
    "display(Markdown(\"For skew-normal vs. unit Gaussian: $\\mathcal{{W}}_2={:.4f}$\".format(W_2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f61c08",
   "metadata": {},
   "source": [
    "This comes out a larger for the Student-$t$. Like the Q-Q plot, the Wasserstein distance is more sensitive to the tails of the distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55482a13",
   "metadata": {},
   "source": [
    "Of course, for simple distributions like these, the quantile functions and cumulative distribution functions can be computed easily, so we can plot them directly to check that things look right. Helpfully, `scipy.stats` gives us everything we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4046b712",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = np.linspace(0, 1, 1000)\n",
    "x = np.linspace(-5, 5, 100)\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(12, 4))\n",
    "ax[0].plot(x, ss.norm.pdf(x), color=\"tab:blue\")\n",
    "ax[0].plot(x, ss.t.pdf(x, df=2), color=\"tab:orange\")\n",
    "ax[0].plot(x, ss.skewnorm.pdf(x, a=2), color=\"tab:green\")\n",
    "ax[0].set_xlabel(\"$x$\")\n",
    "ax[0].set_ylabel(\"$P(x)$\")\n",
    "ax[0].set_xlim(-3, 3)\n",
    "ax[0].set_ylim(0, None)\n",
    "\n",
    "# the ppf method of any scipy.stats distribution gives the quantile function\n",
    "x_ref_quantiles = ss.norm.ppf(p)\n",
    "ax[1].plot([-3, 3], [-3, 3], color=\"tab:blue\", linestyle=\"--\")\n",
    "ax[1].plot(x_ref_quantiles, ss.t.ppf(p, df=2), color=\"tab:orange\")\n",
    "ax[1].plot(x_ref_quantiles, ss.skewnorm.ppf(p, a=2), color=\"tab:green\")\n",
    "ax[1].set_xlim(-3, 3)\n",
    "ax[1].set_ylim(-3, 3)\n",
    "ax[1].set_xlabel(\"$x^\\\\mathrm{ref}$ quantiles\") \n",
    "ax[1].set_ylabel(\"$x^\\\\mathrm{alt}$ quantiles\")\n",
    "\n",
    "# the ppf method of any scipy.stats distribution gives the quantile function\n",
    "x_ref_cumprobs = ss.norm.cdf(x)\n",
    "ax[2].plot([0, 1], [0, 1], color=\"tab:blue\", linestyle=\"--\")\n",
    "ax[2].plot(x_ref_cumprobs, ss.t.cdf(x, df=2), color=\"tab:orange\")\n",
    "ax[2].plot(x_ref_cumprobs, ss.skewnorm.cdf(x, a=2), color=\"tab:green\")\n",
    "ax[2].set_xlim(0, 1)\n",
    "ax[2].set_ylim(0, 1)\n",
    "ax[2].set_xlabel(\"$x^\\\\mathrm{ref}$ cumulative prob.\") \n",
    "ax[2].set_ylabel(\"$x^\\\\mathrm{alt}$ cumulative prob.\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765ce459",
   "metadata": {},
   "source": [
    "That looks good! And it might look familiar from Figure 1 of the paper."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cab7692",
   "metadata": {},
   "source": [
    "## Two-Dimensional Example\n",
    "\n",
    "Now, let's try a two-dimensional problem. We can try a combination of distributions from Figure 3 of the paper, with a multivariate Gaussian as our reference distribution. Alternative \"A\" will be a rotated version of this, and alternative \"B\" will be a multivariate Student-$t$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e00a9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 4000\n",
    "Sigma = np.array([[1.0, 0.75],[0.75, 1.0]]) # covariance/shape matrix\n",
    "X_ref = ss.multivariate_normal.rvs(cov=Sigma, size=N) # multivariate normal\n",
    "X_A = ss.multivariate_normal.rvs(cov=[[1.0, -0.75],[-0.75, 1.0]], size=N) # rotated version\n",
    "X_B = ss.multivariate_t.rvs(shape=Sigma, df=3, size=N) # multivariate t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b3adc5",
   "metadata": {},
   "source": [
    "The bivariate skew-normal we used in the paper isn't in `scipy.stats`. Luckily, it isn't too difficult to generate draws from it. We'll define a function below for this, based on the transformation given in [Azzalini & Capitanio (1999)](https://arxiv.org/abs/0911.2093). We first draw a set of three latent variables $(\\tilde{x}_0, \\tilde{\\mathbf{x}})^\\top$ from a multivariate normal:\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "\\tilde{x}_0\\\\\n",
    "\\tilde{\\mathbf{x}}\n",
    "\\end{bmatrix} \\sim\n",
    "N(\\mathbf{0}, \\mathbf{\\Omega}).\n",
    "$$\n",
    "Where $\\mathbf{\\Omega}$ is a correlation matrix set by three hyperparameters $\\omega$, $\\delta_1$, and $\\delta_2$:\n",
    "$$\n",
    "\\mathbf{\\Omega} = \\begin{bmatrix}\n",
    "1 & \\delta_1 & \\delta_2\\\\\n",
    "\\delta_1 & 1 & \\omega\\\\\n",
    "\\delta_2 & \\omega & 1\n",
    "\\end{bmatrix}.\n",
    "$$\n",
    "Then, we can generate a sample $\\mathbf{x}$ from a bivariate skew-normal by taking:\n",
    "$$\n",
    "\\mathbf{x} = \\begin{cases}\n",
    "\\tilde{\\mathbf{x}} &\\text{ if } \\tilde{x}_0>0\\\\\n",
    "-\\tilde{\\mathbf{x}} &\\text{ otherwise}\n",
    "\\end{cases}.\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cbb6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bivariate_skewn_rvs(omega, del1, del2, N):\n",
    "    \"\"\"\n",
    "    Generate bivariate skew-normal random variables.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    omega : float\n",
    "        Correlation\n",
    "    del1 : float\n",
    "        Shape parameter within [-1, 1]\n",
    "    del2 : float\n",
    "        Shape parameter within [-1, 1]\n",
    "    N : int\n",
    "        Number of samples to draw\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    X : numpy.array\n",
    "        Array of shape (N,2) containing draws\n",
    "    \"\"\"\n",
    "    Omega = np.eye(3)\n",
    "    Omega[2,1] = omega\n",
    "    Omega[1,2] = omega\n",
    "    Omega[0,1] = del1\n",
    "    Omega[0,2] = del2\n",
    "    Omega[1,0] = del1\n",
    "    Omega[2,0] = del2\n",
    "    X_tilde = np.random.multivariate_normal(mean=np.zeros(3), cov=Omega, size=N)\n",
    "    X = np.zeros((N,2))\n",
    "    pos = X_tilde[:,0] > 0\n",
    "    X[pos,:] = X_tilde[pos,1:]\n",
    "    X[~pos,:] = -X_tilde[~pos,1:]\n",
    "    return X\n",
    "\n",
    "# draw from a bivariate skew normal (we'll do something symetric)\n",
    "X_C = bivariate_skewn_rvs(0.75, 0.75, 0.75, N)\n",
    "# let's plot the samples from this, to see what they look like compared to the reference\n",
    "plt.plot(X_ref[:,0], X_ref[:,1], color=\"tab:blue\", marker=\".\", linestyle=\"\", alpha=0.1, label=\"Norm.\")\n",
    "plt.plot(X_C[:,0], X_C[:,1], markerfacecolor=\"none\", markeredgecolor=\"tab:green\", marker=\".\", linestyle=\"\", alpha=0.2, label=\"Skew-norm.\")\n",
    "plt.legend(frameon=False, loc=\"upper left\")\n",
    "plt.xlabel(\"$x_{1}$\")\n",
    "plt.ylabel(\"$x_{2}$\")\n",
    "plt.xlim(-4, 4)\n",
    "plt.ylim(-4, 4)\n",
    "plt.gca().set_aspect(\"equal\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03173aed",
   "metadata": {},
   "source": [
    "Now, lets compare the distributions along the first principal axis of the reference sample. First, we'll use the `pca` function from our `quantile_utilities` library to find the principal axes of $\\mathbf{X}^\\text{ref}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2254bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_ref, V_ref, Y_ref = qu.pca(X_ref)\n",
    "\n",
    "display(Markdown(\"Eigenvalues: $\\mathbf{{\\lambda}}^\\\\mathrm{{ref}}=[{:.3f}, {:.3f}]^\\\\top$\".format(*l_ref)))\n",
    "display(Markdown(\"First eigenvector: $\\mathbf{{v}}_1^\\\\mathrm{{ref}}=[{:.3f}, {:.3f}]^\\\\top$\".format(*V_ref[:,0])))\n",
    "display(Markdown(\"Second eigenvector: $\\mathbf{{v}}_2^\\\\mathrm{{ref}}=[{:.3f}, {:.3f}]^\\\\top$\".format(*V_ref[:,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1638edb",
   "metadata": {},
   "source": [
    "It looks like the first component accounts for a lot more of the variance in $\\mathbf{X}^\\text{ref}$, and is roughly parallel to the diagonal. Now we can project the other samples along the same axes by multiplying them into $\\mathbf{v}_1^\\text{ref}$. So for a general alternate distribution, $\\mathbf{y}_1^\\text{alt} = \\mathbf{X}^\\text{alt}\\cdot\\mathbf{v}_1^\\text{ref}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d4d945",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_A = X_A @ V_ref[:,0]\n",
    "Y_B = X_B @ V_ref[:,0]\n",
    "Y_C = X_C @ V_ref[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfdba17",
   "metadata": {},
   "source": [
    "And now, we can make some Q-Q and P-P plots to compare the distributions along this axis. This time, we'll make an \"unbinned\" Q-Q plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3885dd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# Q-Q plots\n",
    "qu.qq_plot(Y_ref[:,0], Y_A, Q=None, B=200, ax=ax[0], color=\"tab:red\", xlabel=\"$y_1^\\\\mathrm{ref}$ quantiles\", ylabel=\"$y_1^\\\\mathrm{alt}$ quantiles\") # rotated normal\n",
    "qu.qq_plot(Y_ref[:,0], Y_B, Q=None, B=None, ax=ax[0], color=\"tab:orange\", xlabel=\"$y_1^\\\\mathrm{ref}$ quantiles\", ylabel=\"$y_1^\\\\mathrm{alt}$ quantiles\", diag_linestyle=\"\") # Student-t\n",
    "qu.qq_plot(Y_ref[:,0], Y_C, Q=None, B=None, ax=ax[0], color=\"tab:green\", xlabel=\"$y_1^\\\\mathrm{ref}$ quantiles\", ylabel=\"$y_1^\\\\mathrm{alt}$ quantiles\", diag_linestyle=\"\") # skew normal\n",
    "ax[0].set_xlim(-4, 4)\n",
    "ax[0].set_ylim(-4, 4)\n",
    "\n",
    "# P-P plots\n",
    "qu.pp_plot(Y_ref[:,0], Y_A, Q=None, B=200, ax=ax[1], color=\"tab:red\", xlabel=\"$y_1^\\\\mathrm{ref}$ cumulative prob.\", ylabel=\"$y_1^\\\\mathrm{alt}$ cumulative prob.\") # rotated normal\n",
    "qu.pp_plot(Y_ref[:,0], Y_B, Q=None, B=None, ax=ax[1], color=\"tab:orange\", xlabel=\"$y_1^\\\\mathrm{ref}$ cumulative prob.\", ylabel=\"$y_1^\\\\mathrm{alt}$ cumulative prob.\", diag_linestyle=\"\") # Student-t\n",
    "qu.pp_plot(Y_ref[:,0], Y_C, Q=None, B=None, ax=ax[1], color=\"tab:green\", xlabel=\"$y_1^\\\\mathrm{ref}$ cumulative prob.\", ylabel=\"$y_1^\\\\mathrm{alt}$ cumulative prob.\", diag_linestyle=\"\") # skew normal\n",
    "ax[1].set_xlim(0, 1)\n",
    "ax[1].set_ylim(0, 1)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8af926",
   "metadata": {},
   "source": [
    "Hopefully these will look familiar from Figure 3 of the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d9ef88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
